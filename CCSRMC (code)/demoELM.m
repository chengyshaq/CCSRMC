warning off %#ok<WNOFF>
clear;clc

addpath(genpath('.'));
starttime = datestr(now,0);

load 'data\Computers.mat';
if exist('train_targets','var')==1&&exist('test_targets','var')==1
    test_target=test_targets';
    train_target=train_targets';
    clear train_targets test_targets 
end 

train_target(train_target==-1)=0;
test_target(test_target==-1)=0;
%% Optimization Parameters
optmParameter.alpha   = 2^-6 ;  
optmParameter.beta    = 2^-3 ; 
optmParameter.gamma   = 2^-4; 
optmParameter.theta   = 1;
optmParameter.lambda   = 2^-6;

optmParameter.maxIter           = 10;
optmParameter.maxIter2          = 100;
optmParameter.epsilon           = 10^-3;
optmParameter.minimumLossMargin = 10^-5;

optmParameter.maxrho  = 10^10;
optmParameter.rho     = 10^-6;
optmParameter.p       = 10.1;

optmParameter.searchPara = 0; % indicate whether tuning the parameters, {0:not,1:yes}
optmParameter.tuneParaOneTime = 1; % indicate that tuning the parameter one time or tuning it in each fold. {0: each fold,1: only one time}

% for large scale dataset, search ranges for alpha and beta should be set to large values,

optmParameter.alpha_searchrange = 2.^[-6:-1]; 
optmParameter.beta_searchrange  = 2.^[-5:-1];
optmParameter.gamma_searchrange = 2.^[-8,-1];
optmParameter.theta_searchrange = 1.^[0];
% optmParameter.lambda_searchrange = 2.^[-8,1];
optmParameter.bQuiet            = 1;

%% Model Parameters
modelparameter.crossvalidation    = 1; % {0,1}
modelparameter.cv_num             = 5;
modelparameter.L2Norm             = 1; % {0,1}
modelparameter.deleteData         = 1; % {0,1}

%% Train and Test
if modelparameter.crossvalidation==0 
else
%% cross validation
    if exist('train_data','var')==1
        data=[train_data;test_data];
%         data=[train_data;test_train];
        target=[train_target,test_target];
         clear train_data test_data train_target test_target
%         clear train_data test_train train_target test_target
    end
    data     = double(data);
    num_data = size(data,1);
    if modelparameter.L2Norm == 1
            temp_data = data;
            temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
            if sum(sum(isnan(temp_data)))>0
                temp_data = data+eps;
                temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
            end
    else
        temp_data = data;
    end
    if modelparameter.deleteData
        clear data
    end
    
    randorder = randperm(num_data);
    Result_JLCLS  = zeros(16,modelparameter.cv_num);

    for j = 1:modelparameter.cv_num
        fprintf('\n Running Fold - %d/%d \n',j,modelparameter.cv_num);

       %% the training and test parts are generated by fixed spliting with the given random order
        [cv_train_data,cv_train_target,cv_test_data,cv_test_target ] = generateCVSet( temp_data,target',randorder,j,modelparameter.cv_num );
        cv_train_target=cv_train_target';
        cv_test_target=cv_test_target';

       %% Tune the parametes
        if optmParameter.searchPara == 1
            if (optmParameter.tuneParaOneTime == 1) && (exist('BestResult','var')==0)
                fprintf('\n-  parameterization for LSRLSF by cross validation on the training data  -');
                [optmParameter, BestResult ] = LSRLSF_adaptive_validate( cv_train_data, cv_train_target, optmParameter);
            elseif (optmParameter.tuneParaOneTime == 0)
                fprintf('\n-  parameterization for LSRLSF by cross validation on the training data  -');
                [optmParameter, BestResult ] = zhangchao_adaptive_validate( cv_train_data, cv_train_target, optmParameter);
            end
        end
        
       %% If we don't search the parameters, we will run LSRLSF with the fixed parametrs
        [model_2] = LSRLSF(cv_train_data, cv_train_target', optmParameter);
        train_slfeature      = cv_train_data*model_2.W;      
        test_slfeature       = cv_test_data*model_2.W;
%%   ELM
        C=1;
        kernel_type='RBF_kernel';
        kernel_para=1.0;
        [Y,TY] = elm_kernel(test_slfeature,train_slfeature,cv_train_target', C, kernel_type, kernel_para);
        Outputs=TY';
        Pre_Labels=sign(Outputs-0.5);
        Pre_Labels(Pre_Labels==-1)=0;
        
       %% evaluation of LSRLSF
        Result_JLCLS(:,j) = EvaluationAll(Pre_Labels,Outputs,cv_test_target);

    end

   %% the average results of JLCLS
    Avg_Result = zeros(16,2);
    Avg_Result(:,1)=mean(Result_JLCLS,2);
    Avg_Result(:,2)=std(Result_JLCLS,1,2);
    fprintf('\nResults of JLCLS\n');
    PrintResults(Avg_Result);

end
endtime = datestr(now,0);